# MongoDB to Azure Cosmos DB for Mongo DB- Spark Utility User Guide

## Online / Offline Migration Mechanizm

- Offline Migration:  A snapshot based bulk copy from source to target. New data added/updated/deleted on the source after the snapshot will not be copied to the target. The application downtime required will depend on the time taken for the bulk copy activity to complete.

- Online Migration: Apart from the bulk data copy activity done in the offline migration, a change stream monitors all additions/updates/deletes and stores them into an intermediate data store. After the bulk data copy is completed the data in the intermediate is copied to the target to make sure all updates done during the migration process are also copied to the target. The application downtime required will be minimal. </br>

</br>

### Connection Strings 

The migration tool uses connection strings to connect the following resources. 

- Source Mongo DB Cluster/endpoint 
- Target Cosmos DB MongoDB account 

Intermediate Cosmos DB NoSQL account (only in case of Online Migrations)

- Status Cosmos DB NoSQL account

Verify the connection strings by using appropriate utilities to establish connections. In case of network restrictions on the source please refer to the previous section to configure your network settings.

## Configuration JSON Setup

The migration tool configuration setting is supplied via a JSON file. This JSON contains three main blocks. The details of each block and its parameters details are provided below.

### Servers Block

The migration connects to the following resources to process the migration. The server block is used to define the various servers involved and their connection details.

- Source Mongo DB instance/endpoint
- Target Cosmos DB MongoDB account
- Intermediate Cosmos DB NoSQL account (only in case of Online Migrations): When an online migration is performed, the tool starts a change feed tracker to keep track of the updates made to the source while the bulk data migration activities are in progress. This change feed is stored in a Cosmos DB NoSQL account and utilized by the tool to update the target once the bulk data transfer activities are finished.
- Status Cosmos DB NoSQL account:  The migration tool stores its logs in a Cosmos NoSQL account. The debugging process involves examining the following collections in the status server.
  * _status: Each collection that is part of the migration has an entry that provides information about the migration status and the number of records migrated. To understand how to interpret the data within the _status collection, please refer to the appendix below.
  * _error: The migration tool records an entry for all documents that could not be inserted in the first attempt. It logs the document IDs of these failed documents. However, it is possible that these documents were eventually inserted as the job made multiple attempts for failed documents. To understand how to read the entries of this collection, please refer to the appendix below.
Sample Server block shown below.
  <pre>
  <code>
  ...
  "servers": { 
    "sourceServer1": { 
        "type": "MONGODB", 
        "name": "sourceServer1", 
        "url": "mongodb://.." 
        }, 
    "sourceServer2": { 
        "type": "MONGODB", 
        "name": "sourceServer2", 
        "url": "mongodb://.." 
        }, 
    "destinationServer": { 
        "type": "MONGODB", 
        "name": "destinationServer", 
        "url": "mongodb://.." 
        }, 
    "intermediateServer": { 
        "type": "COSMOSDB", 
        "name": "intermediateServer", 
        "url": "https://..", 
        "key": ".." 
        }, 
    "statusServer": { 
       "type": "COSMOSDB", 
       "name": "statusServer", 
       "url": "https://..", 
       "key": ".." 
       } 
  } 
  ...
  </code>
  </pre>
Note:
- Both source and destination servers need to support MongoDB APIs and require the connection string to be specified in the JSON. 
- Intermediate and status servers are Cosmos DB for NOSQL servers, requiring endpoint and key specifications. 
- Connectivity to all 4 endpoints from Azure Data Bricks cluster is necessary. 
- The server names (e.g. statusServer, destinationServer, sourceServer2) are user-defined label for identifying the server in the JSON. The same names are used in the Tasks block to reference the server. 

## Environment Setup

This phase is premigration and involves the estimations and network configuration related activities required to have a seamless migration experience. </br>

